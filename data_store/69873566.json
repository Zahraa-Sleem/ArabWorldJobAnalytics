{
    "Job ID": "69873566",
    "Description": "Are you passionate about data? Does the prospect of dealing with massive volumes of data excite you? Do you want to build data engineering solutions that process billions of records a day in a scalable fashion using AWS technologies? Do you want to create the next-generation tools for intuitive data access?\nBooks purchase and payment experience team is seeking an outstanding Data Engineer to join the team that is shaping the future of the Books purchase experience. The team is committed to building the next generation data platform to support Amazon's rapidly growing and dynamic business, and use it to deliver the BI applications which will have an immediate influence on day-to-day decision making. Amazon has culture of data-driven decision-making, and demands data that is timely, accurate, and actionable. Our platform serves Amazon's Books customers across the globe.\nAs a Data Engineer, you should be an expert with data warehousing technical components (e.g. Data Modeling, ETL and Reporting), infrastructure (e.g. hardware and software) and their integration. You should have deep understanding of the architecture for enterprise level data warehouse solutions using multiple platforms (RDBMS, Columnar, Cloud). You should be an expert in the design, creation, management, and business use of extremely large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. The individual is expected to be able to build efficient, flexible, extensible, and scalable ETL and reporting solutions. You should be enthusiastic about learning new technologies and be able to implement solutions using them to provide new functionality to the users or to scale the existing platform. Excellent written and verbal communication skills are required as the person will work very closely with diverse teams. Having analytical skills is a plus. Above all, you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change.\nOur ideal candidate thrives in a fast-paced environment, relishes working with large transactional volumes and big data, enjoys the challenge of highly complex business contexts (that are typically being defined in real-time), and, above all, is a passionate about data and analytics.\nKey job responsibilities\nDesign, implement, and support a platform providing secured access to large datasets.\nModel data and metadata to support ad-hoc and pre-built reporting.\nOwn the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.\nRecognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.\nTune application and query performance using profiling tools and SQL.\nAnalyze and solve problems at their root, stepping back to understand the broader context.\nLearn and understand a broad range of Amazonâ€™s data resources and know when, how, and which to use and which not to use.\nKeep up to date with advances in big data technologies and run pilots to design the data architecture to scale with the increased data volume using AWS.\nContinually improve ongoing reporting and analysis processes, automating or simplifying self-service support for datasets.\nTriage many possible courses of action in a high-ambiguity environment, making use of both quantitative analysis and business judgment.\nWe are open to hiring candidates to work out of one of the following locations:\nChennai, TN, IND\n- 1+ years of data engineering experience\n- Experience with SQL\n- Experience with data modeling, warehousing and building ETL pipelines\n- Experience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala)\n- Experience with one or more scripting language (e.g., Python, KornShell)\n- Experience with big data technologies such as: Hadoop, Hive, Spark, EMR\n- Experience with any ETL tool like, Informatica, ODI, SSIS, BODI, Datastage, etc.Job Details",
    "Skills": [],
    "Preferred": {},
    "Data": {
        "Job Location": "Chennai, India",
        "Company Industry": "Other Business Support Services",
        "Company Type": "Unspecified",
        "Employment Type": "Unspecified",
        "Monthly Salary Range": "Unspecified",
        "Number of Vacancies": "Unspecified"
    }
}